{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../../data/fraud_detection_bank_dataset.csv\")\n",
    "col_names = [f\"col_{i}\" for i in range(111)]\n",
    "target = \"targets\"\n",
    "\n",
    "train_data, test_data = train_test_split(data, train_size=0.8, random_state=123)\n",
    "X_train, y_train = train_data[col_names].values, train_data[target].values\n",
    "X_test, y_test = test_data[col_names].values, test_data[target].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Stump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-Code\n",
    "\n",
    "  Input: Feature Matrix X and  label vector y\n",
    "\n",
    "  ``` \n",
    "    for each feature j ('Column' of X)\n",
    "        for each threshold t\n",
    "            set `y_yes` to most commom label of obejects i satisfying rule (xij > t)\n",
    "            set `y_no` to most commom label of obejects i not satisfying rule (xij <= t)\n",
    "            set `y_hat` to be prediction\n",
    "            compute error\n",
    "            store the rule (j, t, y_yes, y_no), if it has the lowest error\n",
    "  ```\n",
    "\n",
    "### Cost of Decision Stumps\n",
    "\n",
    "Assume we have:\n",
    "\n",
    "   - ‘n’ examples (days that we measured).\n",
    "\n",
    "   - ‘d’ features (foods that we measured).\n",
    "\n",
    "   - ‘k’ thresholds (>0, >1, >2, …) for each feature\n",
    "\n",
    "   - final cost is $O(ndk)$, assume k=n, then it is $O(n^2d)$\n",
    "\n",
    "\n",
    "### Improvement\n",
    "\n",
    "  - Accuracy is not a good way to split the feature.\n",
    "\n",
    "  - $O(n^2d)$ can be improved to $O(ndlog(n))$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    \n",
    "    return (y == y_hat).sum() / len(y)\n",
    "\n",
    "\n",
    "class Decision_stump():\n",
    "\n",
    "    def fit(self, X, y):\n",
    "    \n",
    "        accu_max = -np.inf\n",
    "        model = []\n",
    "\n",
    "        for idx, feature in enumerate(X.T):\n",
    "            \n",
    "            threshs = set(feature)\n",
    "            for thresh in threshs:\n",
    "                \n",
    "                y_yes = y[feature > thresh]\n",
    "                y_no = y[feature <= thresh]\n",
    "                \n",
    "                if y_yes.sum() < int(0.5 * len(y_yes)):\n",
    "                    y_hat_yes = np.zeros_like(y_yes)\n",
    "                else:\n",
    "                    y_hat_yes = np.ones_like(y_yes)\n",
    "                    \n",
    "                if y_no.sum() < int(0.5 * len(y_no)):\n",
    "                    y_hat_no = np.zeros_like(y_no)\n",
    "                else:\n",
    "                    y_hat_no = np.ones_like(y_no)\n",
    "\n",
    "                y_hat_con = np.concatenate([y_hat_yes, y_hat_no])\n",
    "                y_con = np.concatenate([y_yes, y_no])\n",
    "\n",
    "                accu = accuracy(y_hat_con, y_con)\n",
    "                if accu > accu_max:\n",
    "                    model = [idx, thresh, accu, y_hat_yes[0], y_hat_no[0]]\n",
    "                    accu_max = accu\n",
    "        \n",
    "        self.model = model        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        idx, thresh, _, y_yes_fill, y_no_fill = self.model\n",
    "        prediction = np.where(X[:, idx]>thresh, y_yes_fill, y_no_fill)\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8229510199096128\n",
      "Test accuracy:  0.8346360527601367\n"
     ]
    }
   ],
   "source": [
    "decision_stump = Decision_stump()\n",
    "decision_stump.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = decision_stump.predict(X_train)\n",
    "y_test_hat = decision_stump.predict(X_test)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy(y_train, y_train_hat))\n",
    "print(\"Test accuracy: \", accuracy(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[83, 0.0, 0.8229510199096128, 1, 0]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_stump.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $O(n^2d)$ can be improved to $O(ndlog(n))$\n",
    "\n",
    "<img src=\"./decision_tree_1.jpg\" width=600 height=300>\n",
    "\n",
    "  - pre-order every feature, it took nlog(n), then repeat for d times\n",
    "\n",
    "  - I tried the algorithm above, but maybe because of numpy's efficiency, I somehow didn't get a faster version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_stump():\n",
    "\n",
    "    def fit(self, X, y):\n",
    "    \n",
    "        accu_max = -np.inf\n",
    "        model = []\n",
    "\n",
    "        for feat_num, feature in enumerate(X.T):\n",
    "                        \n",
    "            sorted_feature = zip(feature, y)\n",
    "            sorted_feature = sorted(sorted_feature, key=lambda x: x[0], reverse=False)\n",
    "            _, sorted_y = zip(*sorted_feature)\n",
    "\n",
    "\n",
    "            p_count_unsatis, f_count_unsatis = 0, 0\n",
    "            p_count_satis, f_count_satis = sum(sorted_y), len(sorted_y) - sum(sorted_y)\n",
    "\n",
    "            if p_count_satis < f_count_satis:\n",
    "                sorted_y_hat = np.zeros_like(sorted_y)\n",
    "            else:\n",
    "                sorted_y_hat = np.ones_like(sorted_y)\n",
    "\n",
    "\n",
    "            thresh_prev = sorted_feature[0][0]\n",
    "\n",
    "            for idx, (thresh, label) in enumerate(sorted_feature):\n",
    "                \n",
    "                if label == 1:\n",
    "                    p_count_unsatis += 1\n",
    "                    p_count_satis -= 1\n",
    "                else:\n",
    "                    f_count_unsatis += 1\n",
    "                    f_count_satis -= 1\n",
    "                \n",
    "                if thresh != thresh_prev or idx == len(sorted_feature) - 1:\n",
    "                    \n",
    "                    if p_count_unsatis < f_count_unsatis:\n",
    "                        sorted_y_hat[:idx] = 0\n",
    "                    else:\n",
    "                        sorted_y_hat[:idx] = 1\n",
    "                        \n",
    "                    if p_count_satis < f_count_satis:\n",
    "                        sorted_y_hat[idx:] = 0\n",
    "                    else:\n",
    "                        sorted_y_hat[idx:] = 1\n",
    "                        \n",
    "                    \n",
    "                    accu = accuracy(sorted_y, sorted_y_hat)\n",
    "                    if accu > accu_max:\n",
    "                        model = [feat_num, thresh_prev, accu, sorted_y_hat[-1], sorted_y_hat[0]]\n",
    "                        accu_max = accu\n",
    "                        \n",
    "                    thresh_prev = thresh\n",
    "\n",
    "                    \n",
    "        \n",
    "        self.model = model        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        idx, thresh, _, y_yes_fill, y_no_fill = self.model\n",
    "        prediction = np.where(X[:, idx]>thresh, y_yes_fill, y_no_fill)\n",
    "\n",
    "        return prediction\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8229510199096128\n",
      "Test accuracy:  0.8346360527601367\n"
     ]
    }
   ],
   "source": [
    "decision_stump_1 = Decision_stump()\n",
    "decision_stump_1.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = decision_stump_1.predict(X_train)\n",
    "y_test_hat = decision_stump_1.predict(X_test)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy(y_train, y_train_hat))\n",
    "print(\"Test accuracy: \", accuracy(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use entropy instead of using accuracy\n",
    "\n",
    "#### Pseudo-Code\n",
    "\n",
    "  Input: vector y\n",
    "\n",
    "  ``` \n",
    "    counter_dict = dict\n",
    "    for ele feature y\n",
    "      dict[ele] += 1\n",
    "\n",
    "    entropy = 0\n",
    "    for i in dict:\n",
    "      prob = dict[i] / n\n",
    "      entropy -= prob * log(prob)\n",
    "    \n",
    "    return entropy\n",
    "  ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def entropy(y):\n",
    "    \n",
    "    p_dist = np.array(list(Counter(y).values()))\n",
    "    p_dist = p_dist / p_dist.sum()\n",
    "    ent = (-1 * np.log(p_dist) * p_dist).sum()\n",
    "    \n",
    "    return ent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_stump_entropy():\n",
    "    \n",
    "    @staticmethod\n",
    "    def entropy(y):\n",
    "        p_dist = np.array(list(Counter(y).values()))\n",
    "        p_dist = p_dist / p_dist.sum()\n",
    "        ent = (-1 * np.log(p_dist) * p_dist).sum()\n",
    "        return ent\n",
    "\n",
    "    def fit(self, X, y):\n",
    "    \n",
    "        gain_max = -np.inf\n",
    "        model = []\n",
    "        ent_base = entropy(y)\n",
    "\n",
    "        for idx, feature in enumerate(X.T):\n",
    "            \n",
    "            threshs = np.linspace(feature.min(), feature.max(), min(len(set(feature)), 100))\n",
    "            # threshs = set(feature)\n",
    "            \n",
    "            for thresh in threshs:\n",
    "                \n",
    "                y_yes = y[feature > thresh]\n",
    "                y_no = y[feature <= thresh]\n",
    "                \n",
    "                y_hat_yes = int(y_yes.sum() >= int(0.5 * len(y_yes)))\n",
    "                y_hat_no = int(y_no.sum() >= int(0.5 * len(y_no)))\n",
    "                \n",
    "                gain = ent_base - (len(y_yes) * entropy(y_yes) + len(y_no) * entropy(y_no)) / len(y)\n",
    "\n",
    "                if gain > gain_max:\n",
    "                    model = [idx, thresh, gain, y_hat_yes, y_hat_no]\n",
    "                    gain_max = gain\n",
    "                        \n",
    "        self.model = model        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        idx, thresh, _, y_yes_fill, y_no_fill = self.model\n",
    "        prediction = np.where(X[:, idx]>thresh, y_yes_fill, y_no_fill)\n",
    "\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7667033101258092\n",
      "Test accuracy:  0.7657547630679042\n"
     ]
    }
   ],
   "source": [
    "decision_stump_2 = Decision_stump_entropy()\n",
    "decision_stump_2.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = decision_stump_2.predict(X_train)\n",
    "y_test_hat = decision_stump_2.predict(X_test)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy(y_train, y_train_hat))\n",
    "print(\"Test accuracy: \", accuracy(y_test, y_test_hat))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "  - It is a recursive decision stump\n",
    "  - Use tree structure or dict to restore the model. This might cause some difference on the former code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    \n",
    "    def __init__(self, var=None, gain=None, thresh=None, left=None, right=None):\n",
    "        \n",
    "        self.var = var\n",
    "        self.gain = gain\n",
    "        self.thresh = thresh\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        \n",
    "    def inorder(self):\n",
    "        \n",
    "        if self.var is not None:\n",
    "            print(self.var, end=' ')\n",
    "    \n",
    "        if self.left is not None and isinstance(self.left, Tree):\n",
    "            self.left.inorder()\n",
    "        else:\n",
    "            print('leaf', self.left, end=' ')\n",
    "            \n",
    "        if self.right is not None and isinstance(self.right, Tree):\n",
    "            self.right.inorder()\n",
    "        else:\n",
    "            print('leaf', self.right, end=' ')\n",
    "\n",
    "\n",
    "class Decision_stump(Tree):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    @staticmethod\n",
    "    def entropy(y):\n",
    "        p_dist = np.array(list(Counter(y).values()))\n",
    "        p_dist = p_dist / p_dist.sum()\n",
    "        ent = (-1 * np.log(p_dist) * p_dist).sum()\n",
    "        return ent\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        gain_max = -np.inf\n",
    "        ent_base = entropy(y)\n",
    "\n",
    "        for idx, feature in enumerate(X.T):\n",
    "            \n",
    "            threshs = np.linspace(feature.min(), feature.max(), min(len(set(feature)), 100))\n",
    "            \n",
    "            for thresh in threshs:\n",
    "                \n",
    "                y_yes = y[feature > thresh]\n",
    "                y_no = y[feature <= thresh]\n",
    "                \n",
    "                y_hat_yes = int(y_yes.sum() >= int(0.5 * len(y_yes)))\n",
    "                y_hat_no = int(y_no.sum() >= int(0.5 * len(y_no)))\n",
    "                \n",
    "                gain = ent_base - (len(y_yes) * entropy(y_yes) + len(y_no) * entropy(y_no)) / len(y)\n",
    "\n",
    "                if gain > gain_max:\n",
    "\n",
    "                    gain_max = gain\n",
    "                    \n",
    "                    self.var = idx\n",
    "                    self.gain = gain\n",
    "                    self.thresh = thresh\n",
    "                    self.left = y_hat_no   \n",
    "                    self.right = y_hat_yes \n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decision_Tree(Tree):\n",
    "    \n",
    "    def __init__(self, depth=3):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.depth = depth\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, X, y, model=Decision_stump(), cur_level=0,):\n",
    "        \n",
    "        model.fit(X, y)\n",
    "        \n",
    "        # print(cur_level, model.var, model.thresh, model.left, model.right)\n",
    "\n",
    "        if cur_level == self.depth:\n",
    "            return \n",
    "        else:\n",
    "            idx_l, idx_r = X[:, model.var] <= model.thresh, X[:, model.var] > model.thresh\n",
    "            if len(idx_l) > 0:\n",
    "                model.left = Decision_stump()\n",
    "                self.fit(X[idx_l], y[idx_l], model=model.left, cur_level=cur_level+1)\n",
    "            \n",
    "            if len(idx_r) > 0:\n",
    "                model.right = Decision_stump()\n",
    "                self.fit(X[idx_r], y[idx_r], model=model.right, cur_level=cur_level+1)\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, X, model=None):\n",
    "        \n",
    "        if isinstance(model, int) or isinstance(model, float):\n",
    "            return model\n",
    "        \n",
    "        if model is None:\n",
    "            model = self.model\n",
    "            \n",
    "        var = model.var\n",
    "        thresh = model.thresh\n",
    "        \n",
    "        if X[var] > thresh:\n",
    "            return self.predict(X, model.right)\n",
    "        else:\n",
    "            return self.predict(X, model.left)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8861609869304996\n",
      "Test accuracy:  0.8861748900830484\n"
     ]
    }
   ],
   "source": [
    "decision_tree = Decision_Tree(depth=3)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_train_hat = np.apply_along_axis(decision_tree.predict, axis=1, arr=X_train)\n",
    "y_test_hat = np.apply_along_axis(decision_tree.predict, axis=1, arr=X_test)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy(y_train, y_train_hat))\n",
    "print(\"Test accuracy: \", accuracy(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "414fe57d044de946bf9d041c0416f862a87762676867e6c6ae283eee01bd4dcc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
