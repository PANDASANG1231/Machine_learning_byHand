{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./../../data/fraud_detection_bank_dataset.csv\")\n",
    "col_names = [f\"col_{i}\" for i in range(111)]\n",
    "col_names_naive = [x for x in col_names if len(data[x].value_counts().keys()) < 10]\n",
    "target = \"targets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    \n",
    "    return (y == y_hat).sum() / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Model\n",
    "\n",
    "### Bayes theorm\n",
    "\n",
    "<img src=\"./../../imgs/bayes_model/01.bayes.jpg\" width=600 height=300> \n",
    "\n",
    "### Tips\n",
    "\n",
    "  The implement of Bayes is pretty simple, still there are three points pretty important\n",
    "\n",
    "  - Laplace smooth: if variable has K possible values, then $p(x=a|y=0) = \\frac{p(x=a, y=0) + \\beta}{p(y=0) + K*\\beta}$\n",
    "    \n",
    "  - What if the variable is continuous? Does `Laplace smooth` help with continuous variables. No, a continuous variable could have infinite values. **solutions: Guassian Bayes or Discretization continuous variables**\n",
    "  \n",
    "  - Avoiding Underflow: Use log function transfer `multiply` to `add` \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, train_size=0.8, random_state=123)\n",
    "X_train, y_train = train_data[col_names_naive].values, train_data[target].values\n",
    "X_test, y_test = test_data[col_names_naive].values, test_data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Naive_Bayes():\n",
    "       \n",
    "    @staticmethod\n",
    "    def transfer(X, y):\n",
    "        set_label = sorted(set(y))\n",
    "        data_dict = {l:X[y == l] for l in set_label}\n",
    "        return data_dict\n",
    "    \n",
    "    def __init__(self, laplace_dict):\n",
    "\n",
    "        self.laplace_dict = laplace_dict\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        data_dict = self.transfer(X, y)\n",
    "        model = {x:{} for x in data_dict.keys()}\n",
    "        total_sum, K = len(y), len(data_dict.keys())\n",
    "        \n",
    "        for label, X in data_dict.items():\n",
    "            \n",
    "            sample_sum = np.shape(X)[0]\n",
    "            \n",
    "            for idx, feat in enumerate(X.T):\n",
    "                counter = Counter(feat)            \n",
    "                counter = dict(counter)\n",
    "                \n",
    "                laplace_dict = self.laplace_dict[idx]\n",
    "                for k in laplace_dict:\n",
    "                    if k not in counter.keys():\n",
    "                        counter[k] = 1 / (len(laplace_dict) + sample_sum)\n",
    "                    else:\n",
    "                        counter[k] = (counter[k] + 1) / (len(laplace_dict) + sample_sum)\n",
    "                                         \n",
    "                model[label][idx] = counter\n",
    "                \n",
    "            model[label][\"cnt\"] = (sample_sum + 1) / (total_sum + K)\n",
    "              \n",
    "        self.model = model\n",
    "    \n",
    "    def predict(self, X_obs):\n",
    "        \n",
    "        likehoods = np.array([])\n",
    "        labels = np.array([])\n",
    "        for label in self.model.keys():\n",
    "            xx = np.array(list(map(lambda idx: self.model[label][idx[0]][idx[1]], enumerate(X_obs))))\n",
    "            xx = np.append(xx, self.model[label][\"cnt\"])\n",
    "            likehood = np.log(xx).sum()\n",
    "            likehoods = np.append(likehoods, likehood)\n",
    "            labels = np.append(labels, label)\n",
    "            \n",
    "        return labels[np.argmax(likehoods)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplace_dict = {}\n",
    "for idx, feat in enumerate(data[col_names_naive].values.T):\n",
    "    laplace_dict[idx] = np.unique(feat)\n",
    "\n",
    "nb = Naive_Bayes(laplace_dict)\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8521436423598387\n",
      "Test accuracy:  0.8600390815828041\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = np.apply_along_axis(nb.predict, axis=1, arr=X_train)\n",
    "y_test_hat = np.apply_along_axis(nb.predict, axis=1, arr=X_test)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy(y_train, y_train_hat))\n",
    "print(\"Test accuracy: \", accuracy(y_test, y_test_hat))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2935  112]\n",
      " [ 461  586]]\n",
      "0.839541547277937\n",
      "0.559694364851958\n",
      "0.6716332378223496\n",
      "0.8600390815828041\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_hat))\n",
    "print(precision_score(y_test, y_test_hat))\n",
    "print(recall_score(y_test, y_test_hat))\n",
    "print(f1_score(y_test, y_test_hat))\n",
    "print(accuracy_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guassian Naive Bayes Model\n",
    "\n",
    "  - Guassian Distribution: \n",
    "  \n",
    "  <img src=\"./../../imgs/bayes_model/02.Guassian.jpg\" width=350 height=50> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Guassian_Naive_Bayes():\n",
    "    \n",
    "    @staticmethod\n",
    "    def transfer(X, y):\n",
    "        set_label = sorted(set(y))\n",
    "        data_dict = {l:X[y == l] for l in set_label}\n",
    "        return data_dict\n",
    "       \n",
    "    @staticmethod\n",
    "    def get_mean(X):\n",
    "        return X.mean(axis=0)\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_var(X):\n",
    "        return X.var(axis=0) + 1e-6\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        data_dict = self.transfer(X, y)\n",
    "        model = {x:{\"mean\":self.get_mean(data_dict[x]), \"var\":self.get_var(data_dict[x])} for x in data_dict.keys()}\n",
    "        \n",
    "        total_sum = len(y)\n",
    "        for i in data_dict.keys():\n",
    "            model[i][\"cnt\"] = np.log(data_dict[i].shape[0] / total_sum)\n",
    "            \n",
    "        self.model = model\n",
    "        \n",
    "    def cal_guassian(self, X_test, y=0):\n",
    "        \n",
    "        mean = self.model[y][\"mean\"]\n",
    "        var = self.model[y][\"var\"]\n",
    "        return (-((X_test - mean) ** 2) / (2 * var) - np.log(np.sqrt(2 * np.math.pi * var))).sum(axis=1)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        \n",
    "        likehoods = []\n",
    "        labels = np.array([])\n",
    "        for idx, label in enumerate(self.model.keys()):\n",
    "            likehood = self.cal_guassian(X_test, y=label) + self.model[label][\"cnt\"]\n",
    "            likehoods.append(likehood)\n",
    "            labels = np.append(labels, label)\n",
    "            \n",
    "        return labels[np.argmax(np.array(likehoods), axis=0)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "guassian_nb = Guassian_Naive_Bayes()\n",
    "guassian_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8231342372053255\n",
      "Test accuracy:  0.8270639960918417\n"
     ]
    }
   ],
   "source": [
    "y_train_hat = guassian_nb.predict(X_train)\n",
    "y_test_hat = guassian_nb.predict(X_test)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy(y_train, y_train_hat))\n",
    "print(\"Test accuracy: \", accuracy(y_test, y_test_hat))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2743  304]\n",
      " [ 404  643]]\n",
      "0.6789862724392819\n",
      "0.6141356255969437\n",
      "0.6449348044132397\n",
      "0.8270639960918417\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_test_hat))\n",
    "print(precision_score(y_test, y_test_hat))\n",
    "print(recall_score(y_test, y_test_hat))\n",
    "print(f1_score(y_test, y_test_hat))\n",
    "print(accuracy_score(y_test, y_test_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "742871bb6e609255bc28a59b6a1471655ace576fc27277c003267a791c7c9788"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
