{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kd Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append(\"./../../src\")\n",
    "\n",
    "from load_data import gen_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KD-Tree's Theory and Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function list**\n",
    "  \n",
    "  - build_tree: Build a KDTree, store every data in its branchs and leaves. \n",
    "\n",
    "    - `_split_feat`: Assume we already have chosen a feature, find the **median value**, and split the data into left (<median) and right(>median). Then save the feature and split value.       \n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "      _split_feat:\n",
    "        1. Find the feat_id with biggest variance\n",
    "        2. Find the median value of X[feat_id], assume it occurs in the nth sample in data\n",
    "        3. Save feat_id in node.feature, save the Nth sample in node.split\n",
    "        4. Return samples (0 to N-1) as X_left, samples (N+1 to end) as X_right\n",
    "    ```\n",
    "\n",
    "    -  `build_tree`: BFS function. Use breadth first search to buile every node. run the loop until the data can not be spilt.    \n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "      build_tree:\n",
    "        1. Build a Stack, initiate with a null KDTree and data X. stack = [(nd, X)]\n",
    "        2. Take out the first item in stack, use _split_feat(X), save the feature and sample in nd.feature and nd.split.\n",
    "        3. Add (nd.left, X_left), (nd.right, X_right) in the stack\n",
    "        4. Run the loop until there is no item in the stack. In this situation, every node in the KDTree only have one data point,\n",
    "         and every data in the sample are stored in the KDTree.\n",
    "\n",
    "    ```\n",
    "\n",
    "<img src=\"./../../imgs/knn/01.kdtree_build.png\" width=1200 height=300> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  - search_knearest: Use that KDTree, search the top k nearest data.\n",
    "\n",
    "    - `_search`: Given a new data Xi and a current node, search Xi from the KDTree until Xi is at an leafnode. \n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "      _search:\n",
    "        1. Given a data Xi and a node in the KDTree.\n",
    "        2. Check the current feat_id and split_value, if Xi[feat_id] < split_value, go to the left node. Otherwise, go to the right node.\n",
    "        3. Iterate step 2, till the current node is the leaf node.\n",
    "    ```\n",
    "    - `_backtrace`: Given a new data Xi, a current node and a target node, backtrace Xi from the KDTree begining with the current node to the target node. \n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "      _backtrace:\n",
    "        1. Given a data Xi, current node in the KDTree, and the target node in the KDTree.\n",
    "        2. Starting from the current node A, calculate the distance between Xi and node A. If it is smallest, save it in a list.\n",
    "        3. Considering current node's father node B, calculate the distance between Xi and hyper plane PB.\n",
    "            - Explaination! This one is extremely important. if a node's father node's hyper plane is farther away from Xi, \n",
    "            this means all nodes in brother node are even farther. So we dont need to consider those nodes, and go to the father node. \n",
    "            - if this distance is smaller than k smallest nodes in the list, stop backtrace and return brother node\n",
    "            - if this distance is larger than k smallest nodes in the list, go to the father node without checking brother node.\n",
    "        4. Run the loop until the node arrive target node, or we need to check the one brother node first.\n",
    "    ```  \n",
    "    - `search_knearest`: BFS function. Use breadth first search to find k nearest neighbour of X.    \n",
    "    ```\n",
    "    ```\n",
    "    ```\n",
    "      search_knearest:\n",
    "        1. Initiate the stack, stack = [(kdtree.root, kdtree.root, 'f')]. Every item in stack has 3 elements. First one is current node,\n",
    "         the second one is target node, the third one is a sign to determine whether we use backtrace or not.\n",
    "        2. Take the item from stack. \n",
    "            - if sign is \"f\", we need to use _search function to go to the leaf node from current node and use _backtrace.\n",
    "              - if we need to check one brother tree in _traceback, add (brother_node, brother_node, \"f\"), (father_node, kdtree.root, \"b\") \n",
    "              in the stack. \n",
    "            - if sign is \"b\", then we just do _traceback. It is same as below.\n",
    "        3. Run the loop until there is nothing in the stack. During the process, the knearest neighbour is keep changing.\n",
    "    ```   \n",
    "\n",
    "    check the illustrator on youtube: [https://www.youtube.com/watch?v=2SbVSxWGtpI](https://www.youtube.com/watch?v=2SbVSxWGtpI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KD-Tree's Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.father = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.feature = None\n",
    "        self.split = None\n",
    "        \n",
    "    def _str_(self):\n",
    "        feature, split = self.feature, self.split\n",
    "        print(f\"Feature:{feature}, Split_value:{split}\")\n",
    "        \n",
    "    @property\n",
    "    def brother(self):\n",
    "        if self.father is None:\n",
    "            ret = None\n",
    "        else:\n",
    "            if self.father.left is self:\n",
    "                ret = self.father.right\n",
    "            else:\n",
    "                ret = self.father.left\n",
    "        return ret\n",
    "    \n",
    "    \n",
    "class KDTree():\n",
    "    \n",
    "    def __init__(self, k=3):\n",
    "        self.root = Node\n",
    "        self.k = k\n",
    "        \n",
    "    @staticmethod\n",
    "    def distance(p1, p2):\n",
    "        if p1 is None or p2 is None:\n",
    "            return 0\n",
    "        return ((p2 - p1) ** 2).sum() ** 0.5\n",
    "    \n",
    "    @staticmethod\n",
    "    def _split_feat(X):\n",
    "        \n",
    "        feat_idx = np.argmax(X.var(axis=0))\n",
    "        # print(len(X), feat_idx)\n",
    "\n",
    "        if len(X) % 2 == 0:\n",
    "            mid = int(len(X) / 2) - 1\n",
    "        else:\n",
    "            mid = int(len(X) / 2 - 0.5)\n",
    "        \n",
    "        X_sort = X[X[:,feat_idx].argsort()]\n",
    "        split = X_sort[:][mid]\n",
    "        X_left = X_sort[:mid]\n",
    "        X_right = X_sort[mid+1:]\n",
    "        \n",
    "        return feat_idx, split, X_left, X_right\n",
    "    \n",
    "    def _search(self, X_i, node):\n",
    "        \n",
    "        \"\"\"\n",
    "        Search Xi from the KDTree until Xi is at an leafnode.\n",
    "        \n",
    "        Arguments:\n",
    "            Xi[list] -- 1d list with int or float.\n",
    "        \n",
    "        Returns:\n",
    "            node -- Leafnode.\n",
    "        \"\"\"\n",
    "        \n",
    "        while node.left or node.right:\n",
    "\n",
    "            # print(\"feat_idx:{}, Xi value:{}, Node value:{}\".format(node.feature, X_i[node.feature], node.split))\n",
    "                    \n",
    "            if node.left is None:\n",
    "                node = node.right\n",
    "                direct = 'right'\n",
    "            elif node.right is None:\n",
    "                node = node.left\n",
    "                direct = 'left'\n",
    "            else:\n",
    "                if X_i[node.feature] < node.split[node.feature]:\n",
    "                    node = node.left\n",
    "                    direct = 'left'\n",
    "                else:\n",
    "                    node = node.right\n",
    "                    direct = 'right'\n",
    "                    \n",
    "            # print(f\"searching path turn {direct}\")\n",
    "        \n",
    "        # print(\"feat_idx:{}, Xi value:{}, Node value:{}\".format(node.feature, X_i[node.feature], node.split))\n",
    "        return node\n",
    "    \n",
    "    def _get_dist_eu(self, X_i, node):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate euclidean distance between Xi and node.\n",
    "        \n",
    "        Arguments:\n",
    "            Xi[list] -- 1d list with int or float.\n",
    "            nd[node]\n",
    "            \n",
    "        Returns:\n",
    "            float -- Euclidean distance.\n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        return self.distance(X_i, node.split)\n",
    "    \n",
    "    def _get_dist_hyper(self, X_i, node):\n",
    "        \n",
    "        \"\"\"\n",
    "        Calculate euclidean distance between Xi and hyper plane.\n",
    "        \n",
    "        Arguments:\n",
    "            Xi[list] -- 1d list with int or float.\n",
    "            nd[node]\n",
    "            \n",
    "        Returns:\n",
    "            float -- Euclidean distance.\n",
    "        \"\"\"\n",
    "        \n",
    "        feat_idx = node.feature\n",
    "        \n",
    "        return abs(X_i[feat_idx] - node.split[feat_idx])\n",
    "    \n",
    "    def _backtrace(self, X_i, node, root):\n",
    "        \n",
    "        \"\"\"\n",
    "        Backtrace node from the KDTree begining with the leafnode.\n",
    "        \n",
    "        Arguments:\n",
    "            Xi]list] -- 1d list with int or float.\n",
    "        \n",
    "        Returns:\n",
    "            node -- The nearest node to Xi.\n",
    "        \"\"\"\n",
    "        \n",
    "        dist_max = self.kbest[-1][1]\n",
    "        # print(X_i, node.split, root.split)\n",
    "        \n",
    "        while node is not root:\n",
    "                        \n",
    "            dist = self._get_dist_eu(X_i, node)\n",
    "            # print(self.kbest, dist, dist_max)\n",
    "\n",
    "            if dist < dist_max:\n",
    "                self.kbest[-1][1] = dist\n",
    "                self.kbest[-1][0] = node\n",
    "                self.kbest = sorted(self.kbest, key=lambda x:x[1])\n",
    "                dist_max = self.kbest[-1][1]\n",
    "                        \n",
    "            node_father = node.father\n",
    "            \n",
    "            if self._get_dist_hyper(X_i, node_father) <= dist_max:\n",
    "                return [(node.brother, node.brother, \"f\"), (node_father, root, \"b\")]\n",
    "            else:\n",
    "                node = node_father\n",
    "            \n",
    "        dist = self._get_dist_eu(X_i, node)\n",
    "        if dist < dist_max:\n",
    "            self.kbest[-1][1] = dist\n",
    "            self.kbest[-1][0] = node\n",
    "            self.kbest = sorted(self.kbest, key=lambda x:x[1])\n",
    "        return []\n",
    "    \n",
    "    def show(self):\n",
    "        \n",
    "        queue = [self.root]\n",
    "        \n",
    "        while queue:\n",
    "            nd = queue.pop(0)\n",
    "            feature, split = nd.feature, nd.split\n",
    "            print(f\"Feature:{feature}, Split_value:{split}\")\n",
    "            if nd.left is not None:\n",
    "                queue.append(nd.left)\n",
    "            if nd.right is not None:\n",
    "                queue.append(nd.right)\n",
    "                \n",
    "    def stat_tree(self):\n",
    "        \n",
    "        queue = [(self.root, 0)]\n",
    "        max_depth = -1\n",
    "        leaf_num = 0\n",
    "        \n",
    "        while queue:\n",
    "            \n",
    "            node, depth = queue.pop(0)\n",
    "            \n",
    "            if depth > max_depth:\n",
    "                max_depth = depth\n",
    "                \n",
    "            if node.left is not None:\n",
    "                queue.append((node.left, depth+1))    \n",
    "            \n",
    "            if node.right is not None:\n",
    "                queue.append((node.right, depth+1))\n",
    "                \n",
    "            if node.left is None and node.right is None:\n",
    "                leaf_num += 1\n",
    "            \n",
    "        print(f\"Max_depth of KD-tree: {max_depth}, Leaf number of KD-tree: {leaf_num}\")\n",
    "\n",
    "    \n",
    "    def build_tree(self, X):\n",
    "        \n",
    "        nd = self.root\n",
    "        queue = [(nd, X)]\n",
    "        \n",
    "        while queue:\n",
    "            \n",
    "            nd, X = queue.pop(0)\n",
    "            nd.feature, nd.split, X_left, X_right = self._split_feat(X)\n",
    "            # print(nd.feature, nd.split, len(X_left), len(X_right))\n",
    "            \n",
    "            if len(X_left) != 0:\n",
    "                nd.left = Node()\n",
    "                nd.left.father = nd\n",
    "                queue.append((nd.left, X_left))\n",
    "\n",
    "            if len(X_right) != 0:\n",
    "                nd.right = Node()\n",
    "                nd.right.father = nd\n",
    "                queue.append((nd.right, X_right))\n",
    "    \n",
    "    def search_knearest(self, X_i):\n",
    "        \n",
    "        self.kbest = [[None, np.inf] for _ in range(self.k)]\n",
    "        \n",
    "        node = self.root\n",
    "        queue = [(node, node, \"f\")]\n",
    "        \n",
    "        while queue:\n",
    "    \n",
    "            current, root, sign = queue.pop(0)\n",
    "            \n",
    "            if current is None:\n",
    "                continue\n",
    "            \n",
    "            if sign == \"f\":\n",
    "                current = self._search(X_i, current)\n",
    "                queue += self._backtrace(X_i, current, root)\n",
    "            elif sign == \"b\":\n",
    "                queue += self._backtrace(X_i, current, root)\n",
    "            \n",
    "            # print(self.kbest)\n",
    "            \n",
    "            \n",
    "## Use exhuast search to compare\n",
    "def exhuast_search(X_i, X_train):\n",
    "    \n",
    "    def distance(p1, p2):\n",
    "        if p1 is None or p2 is None:\n",
    "            return 0\n",
    "        return ((p2 - p1) ** 2).sum() ** 0.5\n",
    "\n",
    "    ds = []\n",
    "    for i in X_train:\n",
    "        d = distance(i, X_i)\n",
    "        ds.append([X_i, i, d])\n",
    "        \n",
    "    ds = sorted(ds, key=lambda x:x[2])\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the result of KD-Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Build KD-Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = gen_data(0, 5, 1000, 5, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_depth of KD-tree: 9, Leaf number of KD-tree: 489\n"
     ]
    }
   ],
   "source": [
    "kd_tree = KDTree()\n",
    "\n",
    "kd_tree.build_tree(X_train)\n",
    "\n",
    "kd_tree.stat_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test the code's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of KD search ...\n",
      "Time consumption:0.0003330707550048828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array([0.38702781, 3.91090853, 0.294159  , 3.8063372 , 4.2228834 ]),\n",
       "  array([0.38702781, 3.91090853, 0.294159  , 3.8063372 , 4.2228834 ]),\n",
       "  0.0),\n",
       " (array([0.38702781, 3.91090853, 0.294159  , 3.8063372 , 4.2228834 ]),\n",
       "  array([0.48944018, 4.39072174, 0.8783012 , 3.73667697, 4.97712649]),\n",
       "  1.0750192075329),\n",
       " (array([0.38702781, 3.91090853, 0.294159  , 3.8063372 , 4.2228834 ]),\n",
       "  array([1.17334826, 3.53623598, 0.32819185, 3.9362685 , 4.89778163]),\n",
       "  1.1100483643138432)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result of violate search ...\n",
      "Time consumption:0.007420778274536133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[array([0.38702781, 3.91090853, 0.294159  , 3.8063372 , 4.2228834 ]),\n",
       "  array([0.38702781, 3.91090853, 0.294159  , 3.8063372 , 4.2228834 ]),\n",
       "  0.0],\n",
       " [array([0.38702781, 3.91090853, 0.294159  , 3.8063372 , 4.2228834 ]),\n",
       "  array([0.48944018, 4.39072174, 0.8783012 , 3.73667697, 4.97712649]),\n",
       "  1.0750192075329],\n",
       " [array([0.38702781, 3.91090853, 0.294159  , 3.8063372 , 4.2228834 ]),\n",
       "  array([1.17334826, 3.53623598, 0.32819185, 3.9362685 , 4.89778163]),\n",
       "  1.1100483643138432]]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Result of KD search ...\")\n",
    "\n",
    "X_i = X_train[500]\n",
    "\n",
    "time1 = time.time()\n",
    "kd_tree.search_knearest(X_i)\n",
    "time2 = time.time()\n",
    "print(\"Time consumption:{}\".format(time2 - time1))\n",
    "display([(X_i, x[0].split, x[1]) for x in kd_tree.kbest])\n",
    "\n",
    "print(\"\\r\\nResult of violate search ...\")\n",
    "time1 = time.time()\n",
    "sds = exhuast_search(X_i, X_train)[:3]\n",
    "time2 = time.time()\n",
    "print(\"Time consumption:{}\".format(time2 - time1))\n",
    "display(sds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test 25 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result: All samples num is 25, Correct/Failure:25/0\n"
     ]
    }
   ],
   "source": [
    "X_is = gen_data(0, 5, 25, 5, seed=560)\n",
    "\n",
    "fail_sum, succ_sum = 0, 0\n",
    "\n",
    "for idx, X_i in enumerate(X_is):\n",
    "\n",
    "    rst1 = exhuast_search(X_i, X_train)[:3]\n",
    "    kd_tree.search_knearest(X_i)\n",
    "    rst2 = [[X_i, x[0].split, x[1]] for x in kd_tree.kbest]\n",
    "    \n",
    "    if sum([str(xx) == str(yy) for xx, yy in zip(rst1, rst2)]) != 3:\n",
    "        fail_sum += 1\n",
    "    else:\n",
    "        succ_sum += 1\n",
    "        \n",
    "print(\"Test Result: All samples num is {}, Correct/Failure:{}/{}\".format(fail_sum + succ_sum, succ_sum, fail_sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.39 ms ± 101 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "X_is = gen_data(0, 5, 1, 5)\n",
    "  \n",
    "kd_tree.search_knearest(X_i)\n",
    "rst2 = kd_tree.kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.6 ms ± 61.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "X_is = gen_data(0, 5, 1, 5)\n",
    "  \n",
    "rst1 = exhuast_search(X_i, X_train)[:3]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "742871bb6e609255bc28a59b6a1471655ace576fc27277c003267a791c7c9788"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('522_Group6': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
